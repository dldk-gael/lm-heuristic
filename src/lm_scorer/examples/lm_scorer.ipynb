{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lm-scorer",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnoX4z8Qvbo0",
        "colab_type": "text"
      },
      "source": [
        "# Setup Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Iq4WxoDiV1t3",
        "colab": {}
      },
      "source": [
        "# Install python.\n",
        "!env DEBIAN_FRONTEND=noninteractive apt-get install -y -qq python3 python3-dev python3-venv python3-pip > /dev/null\n",
        "# Upgrade pip\n",
        "!python -m pip install -qq --upgrade pip\n",
        "# Disable TF info logs\n",
        "%env TF_CPP_MIN_LOG_LEVEL=2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dhg7FaKiLdN",
        "colab_type": "code",
        "outputId": "9c3264e3-dd01-47e8-bf08-fc8730d1944a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!python --version\n",
        "!pip --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n",
            "pip 20.0.2 from /usr/local/lib/python3.6/dist-packages/pip (python 3.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIE59LALvjmE",
        "colab_type": "text"
      },
      "source": [
        "# Install lm-scorer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPIZ7D2avgmw",
        "colab_type": "code",
        "outputId": "b6f63c61-d9ea-4767-b00d-972a93824240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!pip install -qq lm-scorer\n",
        "!pip show lm-scorer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: lm-scorer\n",
            "Version: 0.3.0\n",
            "Summary: Language Model based sentences scoring library\n",
            "Home-page: https://github.com/simonepri/lm-scorer#readme\n",
            "Author: Simone Primarosa\n",
            "Author-email: simonepri@outlook.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: transformers, torch, pip\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAWCMVnC9Nqv",
        "colab_type": "text"
      },
      "source": [
        "# Run the CLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGEGKmPoTd5U",
        "colab_type": "code",
        "outputId": "30a69ec0-3411-491b-be88-393aa05ab1db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "!lm-scorer -h"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: lm-scorer [-h] [--model-name MODEL_NAME] [--tokens] [--log-prob]\n",
            "                 [--reduce REDUCE] [--cuda CUDA] [--debug]\n",
            "                 sentences-file-path\n",
            "\n",
            "Get sentences probability using a language model.\n",
            "\n",
            "positional arguments:\n",
            "  sentences-file-path   A file containing sentences to score, one per line. If\n",
            "                        - is given as filename it reads from stdin instead.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model-name MODEL_NAME, -m MODEL_NAME\n",
            "                        The pretrained language model to use. Can be one of:\n",
            "                        gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2.\n",
            "  --tokens, -t          If provided it provides the probability of each token\n",
            "                        of each sentence.\n",
            "  --log-prob, -lp       If provided log probabilities are returned instead.\n",
            "  --reduce REDUCE, -r REDUCE\n",
            "                        Reduce strategy applied on token probabilities to get\n",
            "                        the sentence score. Available strategies are: prod,\n",
            "                        mean, gmean, hmean.\n",
            "  --cuda CUDA           If provided it runs the model on the given cuda\n",
            "                        device.\n",
            "  --debug               If provided it provides additional logging in case of\n",
            "                        errors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHNGxhLbTNVd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fcd38878-f8dd-4251-85d4-eeb343c01092"
      },
      "source": [
        "%%writefile sentences.txt\n",
        "I am going to run a marathon.\n",
        "I am go to run a marathon."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing sentences.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljwsZkjT7QIx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "a10ba46f-fb1b-4df8-c2c7-0fdbbd6cd957"
      },
      "source": [
        "# @markdown The LM model to use.\n",
        "MODEL = 'gpt2'  #@param [\"gpt2\", \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\", \"distilgpt2\"]\n",
        "# @markdown Reduction strategy used to compute the sentence score out of tokens' probabilities.\n",
        "REDUCE = 'prod'  #@param [\"prod\", \"mean\", \"gmean\", \"hmean\"]\n",
        "# @markdown CUDA device id to use (e.g. 0), a negative value disables CUDA accelleration.\n",
        "CUDA = -1  #@param {type: \"number\"}\n",
        "\n",
        "!lm-scorer -m $MODEL -r $REDUCE --cuda $CUDA -lp -t sentences.txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am going to run a marathon.\t-32.551\n",
            "I\t-3.9997\n",
            "Ġam\t-3.0501\n",
            "Ġgoing\t-3.4329\n",
            "Ġto\t-0.075371\n",
            "Ġrun\t-5.6097\n",
            "Ġa\t-1.6184\n",
            "Ġmarathon\t-5.9767\n",
            ".\t-2.3148\n",
            "<|endoftext|>\t-6.4729\n",
            "\n",
            "I am go to run a marathon.\t-42.834\n",
            "I\t-3.9997\n",
            "Ġam\t-3.0501\n",
            "Ġgo\t-10.555\n",
            "Ġto\t-4.5773\n",
            "Ġrun\t-6.7563\n",
            "Ġa\t-1.872\n",
            "Ġmarathon\t-3.8127\n",
            ".\t-1.9487\n",
            "<|endoftext|>\t-6.2627\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
